\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{longtable}
\geometry{margin=2.5cm}

% Portada
\begin{document}
% Portada mejorada
\begin{titlepage}
    \newgeometry{top=3cm,bottom=3cm,left=3.5cm,right=3.5cm}
    \centering
    \vspace*{1cm}
    {\Huge\bfseries Universidad de La Habana\\[0.5em]}
    {\Large Facultad de Ciencias\\[2em]}
    \rule{\textwidth}{1pt}\\[1.5em]
    {\LARGE\bfseries Predicción del coste de la prima “out of pocket”\\de seguro médico en MEPS 2022\\[1.5em]}
    \rule{\textwidth}{1pt}\\[2em]
    \vfill
    {\large\textbf{Autor:} Diego J. Puentes Fernandez\\[0.5em]}
    {\large\textbf{Materia:} Ciencia de Datos}
    \vfill
    \restoregeometry
\end{titlepage}

% Índice
\tableofcontents
\newpage

% Descripción del problema
\section{Descripción del problema}
El objetivo de este trabajo es predecir, a partir de características personales y de salud de los individuos, el coste de la prima “out of pocket” de su seguro médico utilizando técnicas de aprendizaje automático.

% Origen y descripción de los datos
\section{Origen y descripción de los datos}
Los datos utilizados provienen de tres fuentes principales: el Medical Expenditure Panel Survey (MEPS), el Clinical Classifications Software Refined (CCSR) y el Crosswalk for Clinical Information Reporting (CCIR).

\begin{itemize}
    \item \textbf{MEPS}: Encuesta nacional de gastos médicos en Estados Unidos, que recopila información detallada sobre el uso de servicios de salud, gastos y seguros médicos de la población.
    \item \textbf{CCSR}: Herramienta de clasificación que agrupa diagnósticos clínicos de acuerdo a códigos ICD-10, facilitando el análisis de condiciones de salud.
    \item \textbf{CCIR}: Tabla de correspondencia que permite mapear códigos y categorías clínicas de enfermedades crónicas.
\end{itemize}

% Primer procesamiento y mapeo de los datos
\section{Primer procesamiento y mapeo de los datos}
Se implementó una función de mapeo para convertir las columnas de los archivos CSV originales en nombres más entendibles y descriptivos, utilizando los archivos de usuario SAS provistos por MEPS (archivos .txt). Además, se realizó un análisis exploratorio de los datos, cuyos resultados principales se resumen en la siguiente tabla:

\begin{longtable}{|l|l|}
\hline
\textbf{Métrica} & \textbf{Valor} \\
\hline
Total de personas & 22431 \\
Edad (mín, máx, Q1, Q3, media, mediana) & 0.0, 85.0, 23.0, 64.0, 43.56, 45.0 \\
\hline
\multicolumn{2}{|c|}{\textbf{Cantidad de personas por raza}} \\
\hline
Non-Hispanic White only & 12211 \\
Hispanic & 4883 \\
Non-Hispanic Black only & 3244 \\
Non-Hispanic Asian only & 1220 \\
Non-Hispanic Other/multi-race & 873 \\
\hline
\multicolumn{2}{|c|}{\textbf{Cantidad de personas por estado civil}} \\
\hline
Married & 8602 \\
Never married & 5495 \\
Under 16 - not applicable & 3765 \\
Divorced & 2546 \\
Widowed & 1619 \\
Separated & 397 \\
-7 & 6 \\
-8 & 1 \\
\hline
\multicolumn{2}{|c|}{\textbf{Cantidad de personas por región}} \\
\hline
South & 8602 \\
West & 5693 \\
Midwest & 4498 \\
Northeast & 3443 \\
Inapplicable & 195 \\
\hline
\multicolumn{2}{|c|}{\textbf{Cantidad de personas por categoría de pobreza}} \\
\hline
High income & 8282 \\
Middle income & 6269 \\
Poor/negative & 3725 \\
Low income & 3105 \\
Near poor & 1050 \\
\hline
Condiciones médicas distintas & 206 \\
Media de condiciones por persona & 4.80 \\
Top 5 condiciones más comunes & CIR007: 5391, END010: 4268, MUS010: 3061, END002: 2334, MBD005: 2158 \\
\hline
\end{longtable}

% Descripción de la variable objetivo
\section{Descripción de la variable objetivo}
La variable objetivo es \texttt{prima out of pocket editada}, que es la prima mensual que pagan las personas por mantener su seguro médico, arreglada por el MEPS después de corregir errores (por eso el "editada"). Sus detalles son:

\begin{itemize}
    \item Entradas válidas: 10189
    \item Mínimo: 1.00
    \item Máximo: 4583.33
    \item Media: 358.37
    \item Mediana: 270.83
    \item Q1: 136.00
    \item Q3: 478.83
    \item Varianza: 113310.34
    \item Desviación estándar: 336.62
    \item Dispersión (máx - mín): 4582.33
    \item Cantidad de outliers (|z|>3): 186
\end{itemize}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{distribucionvariableobjetivo.png}
    \caption{Distribución de la variable objetivo}
\end{figure}

% Caracterización de outliers de la variable objetivo
\section{Caracterización de outliers de la variable objetivo}
A continuación se presenta un panorama general de las personas que son outliers en la variable objetivo, comparando sus características respecto al grupo general. Se observa que no presentan diferencias extremas ni especiales, por lo que se decidió prescindir de ellos para el entrenamiento de los modelos.

\begin{longtable}{|l|c|c|}
\hline
\textbf{Métrica} & \textbf{Outliers} & \textbf{Resto} \\
\hline
Cantidad de outliers (|z|>3) & 186 & 10003 \\
Porcentaje de outliers & 1.83\% & 98.17\% \\
Media de edad & 36.76 & 42.13 \\
Media de ccsr\_num\_total & 2.15 & 2.96 \\
Media de ccsr\_otra\_condicion & 1.78 & 2.26 \\
Proporción sexo\_Male & 0.46 & 0.48 \\
region\_Midwest & 0.27 & 0.23 \\
region\_Northeast & 0.18 & 0.17 \\
region\_South & 0.19 & 0.35 \\
region\_West & 0.35 & 0.26 \\
estado\_civil\_Married & 0.55 & 0.48 \\
estado\_civil\_Never married & 0.20 & 0.23 \\
estado\_civil\_Separated & 0.00 & 0.01 \\
estado\_civil\_Under 16 - not applicable & 0.23 & 0.15 \\
estado\_civil\_Widowed & 0.01 & 0.04 \\
raza\_etnicidad\_Non-Hispanic Asian only & 0.06 & 0.07 \\
raza\_etnicidad\_Non-Hispanic Black only & 0.04 & 0.11 \\
raza\_etnicidad\_Non-Hispanic Other race or multi-race & 0.02 & 0.04 \\
raza\_etnicidad\_Non-Hispanic White only & 0.74 & 0.64 \\
ccsr\_Essential hypertension & 0.13 & 0.21 \\
ccsr\_Disorders of lipid metabolism & 0.11 & 0.16 \\
ccsr\_Diabetes mellitus without complication & 0.02 & 0.08 \\
ccsr\_Bacterial infections & 0.01 & 0.02 \\
ccsr\_Osteoarthritis & 0.02 & 0.06 \\
ccsr\_Cataract and other lens disorders & 0.01 & 0.02 \\
ccsr\_Esophageal disorders & 0.02 & 0.06 \\
ccsr\_Retinal and vitreous conditions & 0.01 & 0.02 \\
ccsr\_Other general signs and symptoms & 0.02 & 0.03 \\
ccsr\_Abnormal findings without diagnosis & 0.01 & 0.02 \\
\hline
\end{longtable}




\section{Primera Propuesta de Modelo}
A partir de los datos obtenidos y procesados, se construyó un dataset final con las siguientes columnas principales. En la siguiente tabla se indica si la columna se mantuvo igual, se le aplicó codificación (encoding) y el tipo de transformación realizada, de acuerdo al script de procesamiento:

\begin{longtable}{|l|l|}
\hline
\textbf{Columna} & \textbf{Tipo de transformación} \\
\hline
edad & - \\
estado\_salud\_percibido & Label Encoding (ordinal) \\
ccsr\_num\_total & - \\
ccsr\_otra\_condicion & - \\
categoria\_pobreza & Label Encoding (ordinal) \\
tiene\_historial\_empleo & Binaria (1 si tiene historial, 0 si no) \\
horas\_por\_semana & Media de horas, imputada si falta \\
sexo\_Male & One-hot encoding (binaria) \\
raza\_etnicidad\_Non-Hispanic Asian only & One-hot encoding (binaria) \\
raza\_etnicidad\_Non-Hispanic Black only & One-hot encoding (binaria) \\
raza\_etnicidad\_Non-Hispanic Other race or multi-race & One-hot encoding (binaria) \\
raza\_etnicidad\_Non-Hispanic White only & One-hot encoding (binaria) \\
estado\_civil\_Married & One-hot encoding (binaria) \\
estado\_civil\_Never married & One-hot encoding (binaria) \\
estado\_civil\_Separated & One-hot encoding (binaria) \\
estado\_civil\_Under 16 - not applicable & One-hot encoding (binaria) \\
estado\_civil\_Widowed & One-hot encoding (binaria) \\
region\_Midwest & One-hot encoding (binaria) \\
region\_Northeast & One-hot encoding (binaria) \\
region\_South & One-hot encoding (binaria) \\
region\_West & One-hot encoding (binaria) \\
ccsr\_Essential hypertension & One-hot encoding (binaria, top 10 CCSR) \\
ccsr\_Disorders of lipid metabolism & One-hot encoding (binaria, top 10 CCSR) \\
ccsr\_Diabetes mellitus without complication & One-hot encoding (binaria, top 10 CCSR) \\
ccsr\_Bacterial infections & One-hot encoding (binaria, top 10 CCSR) \\
ccsr\_Osteoarthritis & One-hot encoding (binaria, top 10 CCSR) \\
ccsr\_Cataract and other lens disorders & One-hot encoding (binaria, top 10 CCSR) \\
ccsr\_Esophageal disorders & One-hot encoding (binaria, top 10 CCSR) \\
ccsr\_Retinal and vitreous conditions & One-hot encoding (binaria, top 10 CCSR) \\
ccsr\_Other general signs and symptoms & One-hot encoding (binaria, top 10 CCSR) \\
ccsr\_Abnormal findings without diagnosis & One-hot encoding (binaria, top 10 CCSR) \\
seguro\_Public only & One-hot encoding (binaria) \\
seguro\_Uninsured & One-hot encoding (binaria) \\
prima\_out\_of\_pocket\_editada & Variable objetivo (sin transformación) \\
\hline
\end{longtable}

El dataset resultante permite representar de forma numérica y categórica las principales características demográficas, socioeconómicas y de salud de cada individuo, facilitando su uso en modelos de aprendizaje automático supervisado.

\vspace{1em}
\noindent
La distribución de las principales variables del dataset final se muestra a continuación. Estas visualizaciones permiten apreciar la diversidad y balance de los datos empleados para el modelado:

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.49\textwidth]{sexo.png}
    \includegraphics[width=0.49\textwidth]{region.png}
    \caption{Distribución de sexo y región}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.55\textwidth]{etnia.png}
    
    \caption{Distribución por etnia}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.80\textwidth]{enfermedades.png}
    \vspace{4,0cm}
    \includegraphics[width=0.80\textwidth]{variable.png}
    \caption{Distribución por enfermedades y variable objetivo}
\end{figure}

\subsection*{Justificación de la selección de modelo}
La selección del modelo para la predicción de la prima “out of pocket” se fundamentó en la exploración de la relación entre las variables predictoras y la variable objetivo. El análisis exploratorio mostró que la relación entre las variables independientes y la prima no es lineal, lo que sugiere que modelos lineales simples pueden no capturar adecuadamente la complejidad de los datos.

No obstante, como punto de partida y para establecer una línea base de comparación, se implementó primero una regresión lineal. Esto permitió obtener una referencia inicial del desempeño y entender las limitaciones de los modelos lineales en este contexto. 

Esta estrategia permitió comparar de manera objetiva los resultados y justificar la necesidad de emplear modelos no lineales para mejorar la capacidad predictiva sobre la variable objetivo.


\subsection*{Resultados del ajuste de modelos y discusión}
Tras el ajuste de hiperparámetros y la comparación de varios modelos (regresión lineal, Random Forest, Gradient Boosting y XGBoost), se observó que ninguno de los modelos logró un desempeño satisfactorio respecto al dataset y la tarea planteada. A continuación se muestra la tabla de métricas obtenidas para cada modelo:

\begin{table}[h!]
    \centering
    \begin{tabular}{lccccc}
        \toprule
        Modelo & MAE & RMSE & $R^2$ & Bias & Varianza \\
        \midrule
        LinearRegression & 191.60 & 252.71 & 0.06 & -0.15 & 4786.28 \\
        RandomForest & 187.35 & 248.62 & 0.09 & 2.86 & 9098.07 \\
        GradientBoosting & 186.89 & 247.47 & 0.09 & 0.84 & 7156.23 \\
        XGBoost & 186.80 & 247.24 & 0.10 & 0.70 & 7099.15 \\
        \bottomrule
    \end{tabular}
    \caption{Comparación de modelos tras ajuste de hiperparámetros.}
\end{table}



Como se aprecia en la tabla y en las gráficas, los valores de $R^2$ son muy bajos (cercanos a cero), y los errores absolutos y cuadráticos medios (MAE y RMSE) son elevados en todos los casos. Incluso tras el ajuste de hiperparámetros, los modelos no logran capturar la complejidad de la variable objetivo ni mejorar significativamente respecto a una predicción trivial. Esto indica que la relación entre las variables predictoras y la prima “out of pocket” es débil o está fuertemente condicionada por factores no presentes en el dataset.

Esta dificultad se explica, en parte, por la naturaleza de la variable objetivo: su distribución es altamente dispersa y presenta una gran cantidad de valores atípicos, como se mostró en el análisis exploratorio. Además, la variable objetivo depende de factores externos (como políticas de aseguradoras, subsidios, condiciones particulares de los individuos) que no están reflejados en las variables disponibles. La combinación de alta dispersión, presencia de outliers y falta de variables explicativas clave limita la capacidad predictiva de los modelos, incluso los más complejos y ajustados.

\begin{figure}
    \centering
    \includegraphics[width=1\textwidth]{modelosmalosajustes.png}
    \caption{Curvas de aprendizaje y ajuste de los modelos principales.}
\end{figure}

En conclusión, los resultados obtenidos muestran que, dadas las características del dataset y la variable objetivo, la predicción precisa de la prima “out of pocket” es una tarea desafiante y limitada con la información disponible.

\vspace{3cm}
\section{Segunda Propuesta de Modelado: Cambiando la Pregunta}
Ante los resultados insatisfactorios obtenidos al intentar predecir el valor exacto de la prima “out of pocket” para cada persona, se exploró un nuevo enfoque de modelado. En lugar de predecir un único valor, se propuso estimar, para cada individuo, un conjunto de tres valores que definan los límites superiores de rangos de conveniencia para la prima esperada, basados en personas similares.

\subsection*{Definición de los rangos de conveniencia}
La idea central es que, para cada persona, el modelo devuelva una lista de tres valores:\\
\begin{itemize}
    \item El primer valor corresponde al límite superior de la categoría \textbf{Excelente}.
    \item El segundo valor es el límite superior de la categoría \textbf{Bueno}.
    \item El tercer valor es el límite superior de la categoría \textbf{Regular}.
\end{itemize}
De este modo, se obtiene un rango personalizado de referencia para la prima, en vez de una predicción puntual, lo que resulta más robusto ante la alta dispersión y variabilidad de la variable objetivo.

\subsection*{Lógica y construcción de los rangos}
Para construir estos límites, se siguió la siguiente lógica:
\begin{enumerate}
    \item Para cada persona del conjunto de test, se identifican los individuos más similares en el conjunto de entrenamiento, utilizando las variables predictoras (excluyendo la variable objetivo para evitar fuga de información).
    \item Sobre el conjunto de personas similares, se calcula la distribución de la prima “out of pocket” y se determinan los percentiles que definen los límites de las categorías: por ejemplo, el percentil 25 para el límite de \textbf{Excelente}, el percentil 50 para \textbf{Bueno} y el percentil 75 para \textbf{Regular}. Estos valores pueden ajustarse según la conveniencia o el criterio del análisis.
    \item Así, para cada persona, el modelo devuelve una terna de valores que acotan los rangos de prima esperada según su perfil, en vez de un único valor.
\end{enumerate}

\subsection*{Prevención de fuga de información}
Un aspecto fundamental de este enfoque es evitar la fuga de información (\textit{data leakage}). Para ello, la búsqueda de personas similares y el cálculo de los rangos se realiza siempre utilizando únicamente el conjunto de entrenamiento, sin acceder a los valores reales de la variable objetivo en el conjunto de test. De este modo, se garantiza que la estimación de los rangos es válida y no está contaminada por información futura o no disponible en un escenario real.

\section{Evaluación de Modelos del Tercer Modelado: Predicción de Límites Personalizados}

En este tercer enfoque, el objetivo fue predecir no un valor único de prima, sino tres límites personalizados (\textbf{Excelente}, \textbf{Bueno}, \textbf{Regular}) para cada persona, utilizando un modelo multisalida (\textit{MultiOutputRegressor}) basado en Random Forest y otros algoritmos. El dataset se dividió en un 70\% para entrenamiento y un 30\% para prueba, asegurando que la construcción de los límites personalizados para cada persona del test se realizó \textbf{sin fuga de información}, es decir, usando sólo los datos de entrenamiento para definir los vecinos y los percentiles.

El ajuste de hiperparámetros se realizó mediante \textbf{GridSearchCV}, probando combinaciones de parámetros para cada modelo y seleccionando la mejor según validación cruzada. Además, se aplicó \textbf{cross-validation} (validación cruzada 5-fold) para estimar el desempeño real de los modelos y evitar sobreajuste.

\subsection*{Comportamiento general del modelo}
El modelo multisalida mostró un desempeño muy superior al de la predicción directa de la prima. Los errores (MAE y RMSE) fueron considerablemente menores y los valores de $R^2$ mucho más altos, indicando que los modelos lograron capturar la estructura de los datos y predecir rangos personalizados de prima con alta precisión. Esto se debe a que el enfoque de rangos es más robusto ante la alta dispersión y variabilidad de la variable objetivo, y aprovecha la información de personas similares en el dataset.

\subsection*{Resultados por límite}
\textbf{Límite Excelente}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{limiteexcelente.png}
    \caption{Curva de aprendizaje para el límite Excelente}
\end{figure}
\begin{table}[h!]
    \centering
    \begin{tabular}{lccccc}
        \toprule
        Modelo & MAE & RMSE & $R^2$ & Bias & Varianza \\
        \midrule
        LinearRegression & 34.89 & 44.95 & 0.23 & -0.03 & 858.45 \\
        GradientBoosting & 15.44 & 21.12 & 0.83 & 0.04 & 2144.26 \\
        RandomForest & 8.74 & 14.28 & 0.92 & -0.04 & 2455.73 \\
        XGBoost & 15.12 & 20.43 & 0.84 & 0.09 & 2113.49 \\
        \bottomrule
    \end{tabular}
    \caption{Métricas para el límite Excelente}
\end{table}

\textbf{Límite Bueno}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{limitebueno.png}
    \caption{Curva de aprendizaje para el límite Bueno}
\end{figure}
\begin{table}[h!]
    \centering
    \begin{tabular}{lccccc}
        \toprule
        Modelo & MAE & RMSE & $R^2$ & Bias & Varianza \\
        \midrule
        LinearRegression & 60.27 & 74.94 & 0.23 & -0.01 & 1771.51 \\
        GradientBoosting & 20.77 & 28.53 & 0.89 & 0.00 & 5222.17 \\
        RandomForest & 18.10 & 26.27 & 0.91 & 0.11 & 5476.06 \\
        XGBoost & 20.59 & 28.37 & 0.89 & 0.10 & 5173.39 \\
        \bottomrule
    \end{tabular}
    \caption{Métricas para el límite Bueno}
\end{table}

\textbf{Límite Regular}
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{limiteregular.png}
    \caption{Curva de aprendizaje para el límite Regular}
\end{figure}
\begin{table}[h!]
    \centering
    \begin{tabular}{lccccc}
        \toprule
        Modelo & MAE & RMSE & $R^2$ & Bias & Varianza \\
        \midrule
        LinearRegression & 90.75 & 115.58 & 0.14 & 0.02 & 2354.56 \\
        GradientBoosting & 34.72 & 49.76 & 0.84 & 0.16 & 10893.46 \\
        RandomForest & 28.69 & 45.16 & 0.87 & 0.11 & 11379.11 \\
        XGBoost & 34.47 & 49.43 & 0.84 & 0.09 & 10713.24 \\
        \bottomrule
    \end{tabular}
    \caption{Métricas para el límite Regular}
\end{table}

\subsection*{Validación cruzada y ajuste de hiperparámetros}
Para cada modelo y cada límite, se realizó validación cruzada 5-fold y ajuste de hiperparámetros. Las siguientes tablas muestran los resultados promedio de validación y entrenamiento para cada modelo y cada límite:

\textbf{Límite Excelente}
\begin{table}[h!]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Modelo & MAE (val) & RMSE (val) & $R^2$ (val) & MAE (train) & RMSE (train) & $R^2$ (train) \\
        \midrule
        LinearRegression & 36.74 & 48.13 & 0.26 & 36.53 & 47.90 & 0.27 \\
        GradientBoosting & 26.37 & 35.66 & 0.60 & 25.82 & 34.82 & 0.62 \\
        RandomForest & 4.71 & 9.22 & 0.97 & 1.81 & 3.57 & 1.00 \\
        XGBoost & 10.83 & 15.36 & 0.92 & 6.58 & 9.63 & 0.97 \\
        \bottomrule
    \end{tabular}
    \caption{Validación cruzada para el límite Excelente}
\end{table}

\textbf{Límite Bueno}
\begin{table}[h!]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Modelo & MAE (val) & RMSE (val) & $R^2$ (val) & MAE (train) & RMSE (train) & $R^2$ (train) \\
        \midrule
        LinearRegression & 61.51 & 75.97 & 0.23 & 61.17 & 75.54 & 0.24 \\
        GradientBoosting & 42.26 & 54.59 & 0.60 & 41.28 & 53.29 & 0.62 \\
        RandomForest & 7.97 & 15.08 & 0.97 & 3.08 & 6.00 & 1.00 \\
        XGBoost & 14.59 & 21.02 & 0.94 & 8.94 & 13.05 & 0.98 \\
        \bottomrule
    \end{tabular}
    \caption{Validación cruzada para el límite Bueno}
\end{table}

\textbf{Límite Regular}
\begin{table}[h!]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Modelo & MAE (val) & RMSE (val) & $R^2$ (val) & MAE (train) & RMSE (train) & $R^2$ (train) \\
        \midrule
        LinearRegression & 91.54 & 115.86 & 0.14 & 91.01 & 115.26 & 0.15 \\
        GradientBoosting & 59.37 & 79.21 & 0.60 & 58.05 & 77.47 & 0.62 \\
        RandomForest & 15.31 & 27.96 & 0.95 & 5.79 & 10.69 & 0.99 \\
        XGBoost & 25.43 & 37.33 & 0.91 & 15.57 & 23.25 & 0.97 \\
        \bottomrule
    \end{tabular}
    \caption{Validación cruzada para el límite Regular}
\end{table}

\subsection*{Discusión de resultados y comparación de modelos}
Los resultados muestran que \textbf{Random Forest} y \textbf{XGBoost} son los modelos con mejor desempeño en la predicción de los límites personalizados, alcanzando valores de $R^2$ superiores a 0.9 y errores absolutos (MAE) muy bajos en comparación con los otros modelos. El modelo Random Forest, en particular, logra el menor MAE y el mayor $R^2$ en los tres límites, lo que lo posiciona como la mejor opción para este problema.

Este enfoque de predicción de rangos funciona mejor que la predicción directa del valor único de la prima porque aprovecha la información de personas similares y reduce el impacto de la alta dispersión y los outliers en la variable objetivo. El dataset favorece este enfoque porque, aunque la relación entre las variables predictoras y la prima es débil para una predicción puntual, sí permite agrupar a las personas en perfiles similares y estimar rangos de referencia mucho más estables y útiles para la toma de decisiones.

\subsection*{Implementación técnica y despliegue}
Para implementar este modelo, se utilizó \textbf{MultiOutputRegressor} con Random Forest, permitiendo predecir los tres límites de manera simultánea y eficiente. El modelo entrenado se exportó y se sirvió a través de una página web interactiva construida con \textbf{Streamlit}, donde los usuarios pueden ingresar sus características y obtener su rango personalizado de prima esperada de forma sencilla y visual.

\section{Conclusiones}
En este trabajo se exploraron diferentes enfoques para la predicción de la prima “out of pocket” de seguro médico usando datos de MEPS 2022. Se demostró que la predicción directa del valor único de la prima es una tarea muy difícil debido a la alta dispersión, presencia de outliers y falta de variables explicativas clave en el dataset. Sin embargo, el enfoque de predicción de límites personalizados basado en personas similares y modelos multisalida permitió obtener resultados mucho más robustos y útiles, con errores bajos y alta capacidad explicativa. La solución final, implementada y desplegada en una interfaz web, permite a los usuarios obtener rangos personalizados de referencia para su prima, facilitando la toma de decisiones informadas y realistas en un contexto de alta incertidumbre y variabilidad.

\end{document}





